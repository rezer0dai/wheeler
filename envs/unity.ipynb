{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MountainCarContinuous-v0 environment of OpenAi GYM \n",
    "- *Wheeler task definition ( task wrapper, State decoder settings, NeuralNetwork, ReplayBuffer, .. )*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import generics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import toml, gym\n",
    "\n",
    "import torch\n",
    "from torch.multiprocessing import Queue, Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load task configs ~ this should be adopted offline for particular task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MountainCarContinuous-v0\n"
     ]
    }
   ],
   "source": [
    "CFG = toml.loads(open('cfg.toml').read())\n",
    "GYM_CFG = toml.loads(open('gym.toml').read())\n",
    "\n",
    "torch.set_default_tensor_type(CFG['tensor'])\n",
    "print(CFG['task'])\n",
    "CFG['task'] = \"unity/Reacher_Linux_20/Reacher.x86_64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import wheeler environment and particular utils we want to use ~ general ones ( shared across tasks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.task import Task\n",
    "from utils.taskinfo import *\n",
    "\n",
    "from utils.rbf import *\n",
    "from utils.normalizer import *\n",
    "\n",
    "from utils.taskmgr import *\n",
    "from utils.replay import *\n",
    "\n",
    "from utils.fastmem import Memory\n",
    "\n",
    "from utils.curiosity import *\n",
    "\n",
    "from agent.zer0bot import agent_launch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Task wrapper ~ when is goal met, how to step ( update rewards function, .. ), when / how to reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymTask(Task):\n",
    "    def reset(self, seed = None, test = False):\n",
    "        cfg = {\"goal_size\":5., \"goal_speed\":1.}\n",
    "        state = super().reset(cfg, test)[0]\n",
    "\n",
    "        if test: return state # we will get array of states\n",
    "\n",
    "        return [state.reshape(-1)]\n",
    "    \n",
    "    def step_ex(self, action, test = False):\n",
    "        state, done, reward = self.env.step(self.bot_id, self.objective_id, action)\n",
    "\n",
    "        if test: return action, state.reshape(1, -1), reward, done, True\n",
    "        \n",
    "        return action, state, reward, done, True\n",
    "\n",
    "    def goal_met(self, states, rewards, n_steps):\n",
    "        print(\"TEST : \", sum(rewards), sum(map(lambda r: r != 0, rewards)), len(rewards))\n",
    "        return sum(abs(r) for r in rewards) > 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic proxy for creating our Task ( multiprocess environments purpose mainly ) \n",
    "- but can also add wrapping function approx values ( action value to tanh, sigmoid, .. ) - this not works well with PPO now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymInfo(TaskInfo):\n",
    "    def __init__(self, replaybuf, factory, Mgr, args):\n",
    "        super().__init__(\n",
    "                33, 4, -1, +1,\n",
    "                CFG,\n",
    "                replaybuf,\n",
    "                factory, Mgr, args)\n",
    "\n",
    "    def new(self, cfg, bot_id, objective_id):\n",
    "        return GymTask(cfg,\n",
    "                self.env,\n",
    "                objective_id, bot_id,\n",
    "                self.action_low, self.action_high)\n",
    "\n",
    "    @staticmethod\n",
    "    def factory(ind): # bare metal task creation\n",
    "        global CFG\n",
    "        from utils.unity import unity_factory\n",
    "        print(\"created %i-th task\"%ind)    \n",
    "        return unity_factory(CFG, CFG['total_simulations'])(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement callback for testing policy ~ per X training rounds, we want to test it ~ enable visuals if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(task, agent, scores):\n",
    "    try: callback.z += 1\n",
    "    except: callback.z = 0\n",
    "    \n",
    "    # we can save scores to main queue, and avarage them, or we can ..\n",
    "    # run testing w/ visuals :\n",
    "    done = all(task.test_policy(agent)[0] for _ in range(10))\n",
    "    if not done:\n",
    "        return False\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"training over\", callback.z * GYM_CFG['n_simulations'] * GYM_CFG['mcts_rounds'])\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for i in range(100): print(\"total steps : training : %i :: %i >\"%(\n",
    "        callback.z * GYM_CFG['mcts_rounds'] * GYM_CFG['n_simulations'],\n",
    "        len(task.test_policy(agent)[2])))\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare neural network which we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ddpg_model, noisy_model, state_action_model\n",
    "\n",
    "def CriticNN(state_size, action_size, wrap_value, cfg):\n",
    "    return state_action_model.Critic(state_size, action_size, wrap_value, cfg, fcs1_units=256, fc2_units=128)\n",
    "    return ddpg_model.Critic(state_size, action_size, wrap_value, cfg, fcs1_units=400, fc2_units=300)\n",
    "\n",
    "def ActorNN(state_size, action_size, wrap_action, cfg):\n",
    "    return noisy_model.Actor(state_size, action_size, wrap_action, cfg, hiddens=[128, 64])\n",
    "    return ddpg_model.Actor(state_size, action_size, wrap_action, cfg, fc1_units=400, fc2_units=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.encoders import *\n",
    "from utils.rnn import *#GRUEncoder\n",
    "\n",
    "def encoderstack():\n",
    "    norm = GlobalNormalizer(GYM_CFG, 33)\n",
    "    return norm\n",
    "    experience = GRUEncoder(GYM_CFG, norm.total_size())#GRU#LSTM\n",
    "    encoder_norm = StackedEncoder(GYM_CFG, 33, norm, experience)\n",
    "    encoder_norm.share_memory()\n",
    "    return encoder_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cook Task : replay buffer ( fast / prio-gae-rnn ) + task manager ( local / remote / unity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taskfactory():\n",
    "#    return GymInfo(Memory, GymInfo.factory, LocalTaskManager, ())\n",
    "#    return GymInfo(ReplayBuffer, GymInfo.factory, LocalTaskManager, ())\n",
    "    return GymInfo(ReplayBuffer, GymInfo.factory, RemoteTaskManager, (LocalTaskManager, 1 + GYM_CFG['n_simulations']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glue it all together ~ select buffer, encoders, agents, ... and RUN!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tensor': 'torch.DoubleTensor', 'task': 'unity/Reacher_Linux_20/Reacher.x86_64', 'total_simulations': 20, 'cross_exp_size': 5000, 'max_reward_val': 1000, 'min_reward_val': -1000}\n",
      "created 0-th task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "INFO:unityagents:\n",
      "Academy Reset with parameters : \tgoal_size -> 5.0, goal_speed -> 1.0\n",
      "Process Process-2:1:\n",
      "Process Process-2:\n",
      "Process RemoteTaskComm-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/xyz/wheeler-v2x/utils/taskmgr.py\", line 23, in run\n",
      "    data = self.pipe_cmd.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/xyz/wheeler-v2x/agent/critic.py\", line 10, in critic_launch\n",
      "    critic.training_loop(share_gate, loss_gate, stats)\n",
      "  File \"/home/xyz/wheeler-v2x/agent/critic.py\", line 47, in training_loop\n",
      "    exp = share_gate.get()\n",
      "  File \"/home/xyz/wheeler-v2x/agent/simulation.py\", line 23, in simulation_launch\n",
      "    sim.explore(loss, mcts, signal, share, stats)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/xyz/wheeler-v2x/agent/simulation.py\", line 55, in explore\n",
      "    scores = self._run(seeds, share_gate, loss_gate, stats)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/xyz/wheeler-v2x/agent/simulation.py\", line 103, in _run\n",
      "    dist, f_pi = self.bot.explore(self.objective_id, state, features[-1])\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/xyz/wheeler-v2x/utils/botproxy.py\", line 29, in explore\n",
      "    history.reshape(1, states.size(0), -1))).to(self.device)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ValueError: cannot reshape array of size 64 into shape (1,20,newaxis)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/util.py\", line 319, in _exit_function\n",
      "    p.join()\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-41e5ac6baee9>\", line 15, in <module>\n",
      "    main()\n",
      "  File \"<ipython-input-10-41e5ac6baee9>\", line 12, in main\n",
      "    agent_launch(0, GYM_CFG, task_factory, encoder, ActorNN, CriticNN, stop_q, callback_task)\n",
      "  File \"/home/xyz/wheeler-v2x/agent/zer0bot.py\", line 34, in agent_launch\n",
      "    scores = agent.train(loss_gate, mcts, signal)\n",
      "  File \"/home/xyz/wheeler-v2x/agent/zer0bot.py\", line 75, in train\n",
      "    self._train_worker(loss)\n",
      "  File \"/home/xyz/wheeler-v2x/agent/zer0bot.py\", line 83, in _train_worker\n",
      "    time.sleep(.1)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/posixpath.py\", line 378, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/xyz/anaconda3/lib/python3.6/posixpath.py\", line 334, in normpath\n",
      "    if isinstance(path, bytes):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/xyz/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(CFG)\n",
    "    \n",
    "    encoder = encoderstack()\n",
    "    task_factory = taskfactory()\n",
    "    task = task_factory.new(GYM_CFG, 0, -1)\n",
    "    \n",
    "    def callback_task(agent, stop_q):\n",
    "        return callback(task, agent, stop_q)\n",
    "    \n",
    "    stop_q = Queue()\n",
    "    agent_launch(0, GYM_CFG, task_factory, encoder, ActorNN, CriticNN, stop_q, callback_task)\n",
    "\n",
    "if '__main__' == __name__:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
